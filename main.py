# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZRxhKl8ioKXBhzGfuxRjCK9Vha5Y6f6Z

# Movie Recommendation System: [TMDB Movies](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata)
- Nama: Mohammad Valeriant Qumara Tanda
- ID: MC180D5Y0566
- Email: valenttanda@gmail.com

## Import Library
Import library yang dibutuhkan untuk proyek ini. Pada proyek ini, digunakan library berikut:
- `pandas`: Mengolah data.
- `numpy`: Melakukan operasi matematika.
- `matplotlib`: Membuat grafik.
- `seaborn`: Membuat grafik yang lebih menarik.
- `ast`: Mengakses atribut dari objek.
- `scikit-learn`: Membuat model rekomendasi dengan TF-IDF dan Cosine Similarity.
- `sentence-transformers`: Membuat model rekomendasi dengan BERT Embeddings. (Untuk menggunakan library ini, disarankan menggunakan IDE Google Colab untuk komputasi yang lebih cepat dan stabil).
- `json`: Menyimpan file ke bentuk JSON.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import ast
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

"""## Load Dataset
Dataset yang digunakan dalam proyek ini adalah dataset kumpulan film dari tahun 1916 hingga 2017. Sumber dataset untuk proyek ini berasal dari [Kaggle](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata).
"""

movie = pd.read_csv("data/tmdb_5000_movies.csv")

"""Tampilkan dataset movie"""

movie.head()

"""## EDA
Di tahap ini, akan dilakukan analisis exploratory data (EDA) untuk memahami data yang ada. EDA ini bertujuan untuk memahami distribusi data, hubungan antar variabel, dan menemukan pola-pola yang ada dalam data. EDA untuk proyek ini hanya mencari informasi dataset, nilai kosong, dan duplikasi data. Ketiga hal di atas dirangkum dalam **Dataset Information**

### Dataset information
Berisikan informasi mengenai dataset yang digunakan. Informasi ini meliputi:
- Bentuk dataset: Mengetahui jumlah kolom dan baris dalam masing-masing dataset
- Informasi dataset: Mengetahui jenis data yang ada dalam dataset, seperti numerik, kategori, atau tanggal, dan secara tidak langsung mengetahui adakah nilai yang hilang dalam dataset atau tidak
- Cek Nilai Kosong: Mengetahui apakah ada nilai kosong dalam dataset atau tidak
- Cek Nilai Duplikat: Mengetahui apakah ada nilai duplikat dalam dataset atau tidak
- Statistik dataset: Mengetahui nilai-nilai statistik dalam dataset

Cek bentuk kedua dataset
"""

print(f"Movie dataframe: {movie.shape}")

"""Cek informasi kedua dataset"""

print(f"{movie.info()}")

"""Dari informasi ini, diketahui bahwa tidak ada nilai kosong pada dataset credit. Selanjutnya, akan diperiksa nilai kosong untuk movie dan duplikasi data untuk kedua dataset

Cek nilai kosong untuk movie
"""

missing_value = movie.isna().sum()
missing_value = missing_value[missing_value > 0]
missing_percentage = (missing_value/len(movie)) * 100
missing_percentage = missing_percentage[missing_percentage > 0]
missing_display = pd.DataFrame({
	'Missing Value': missing_value.sort_values(ascending=False),
  'Missing Percentage': missing_percentage.sort_values(ascending=False).round(4).astype(str) + '%'
})
missing_display

"""Terlihat bahwa `homepage` memiliki nilai kosong paling besar, sekitar 64%. Selain itu, karena `homepage` tidak dibutuhkan dalam analisis mendatang,  maka kolom `homepage` akan dihapus

Cek duplikasi data
"""

print(f"Duplicated data in movie: {movie.duplicated().sum()}")

"""Pada dataset **movie**, terdapat `original_title` dan `title`, sedangkan pada dataset **credit** terdapat `title`. Akan dilakukan pengecekan nilai unik dari masing-masing kolom pada kedua dataset"""

# Unique values
for col in ['original_title', 'title']:
  print(f"Unique values in movie: column {col}: {movie[col].unique()}\n")

"""Ternyata, isi dari ketiga kolom tersebut sama. Oleh karena itu, untuk `title` pada **movie** dan `title` pada **credit** akan dihapus, karena merupakan duplikasi dari kolom `original_title`

Statistik Dataset
"""

movie.describe(include='all')

"""## Preprocessing
Membersihkan dataset dari nilai kosong. Untuk tahap ini, tidak banyak preprocessing yang dilakukan, karena hanya menangani nilai kosong, dan setiap data berbentuk objek diperlukan untuk pemodelan sistem rekomendasi mendatang. Preprocessing ini hanya berfokus pada kolom `overview` dan `genres`

Menghapus kolom yang tidak dibutuhkan:
- `homepage`: memiliki nilai kosong paling banyak (64%).
- `title` pada **credit** dan `title` pada **movie**: keduanya merupakan duplikasi dari `original_title`.
"""

movie_cleaned = movie.drop(columns=['homepage', 'title'])

"""Mengatasi nilai kosong pada `overview`, dengan membuat string kosong."""

movie_cleaned['overview'] = movie_cleaned['overview'].fillna('')

"""## Preparation
Mempersiapkan dataset sebelum pemodelan. Untuk tahap ini, ada beberapa hal yang dikerjakan, seperti:

### 1. Copy Cleaned `movie` to `df` for Modeling
Menyalin dataset `movie` yang telah bersih ke dalam dataset baru `df` untuk persiapan pemodelan
"""

df = movie_cleaned.copy()
df

"""Cek bentuk dataset"""

df.shape

"""Cek informasi dataset"""

df.info()

"""### 2. Drop Unnecessary Columns
Beberapa kolom, seperti `status` dan `production_countries` tidak diperlukan untuk proyek ini, karena tidak menyatakan apa pun dalam sistem rekomendasi. Sehingga, kedua kolom ini dihapus
"""

df = df.drop(columns=['status', 'production_countries'])
df.head()

"""### 3. Parsing `genres` Column

Karena `genres` dibutuhkan dalam sistem rekomendasi, dan bentuk `genres` masih berformat **JSON**, maka perlu dilakukan parsing ke bentuk string.
"""

def clean_genres(genre_str):
  try:
    genres = ast.literal_eval(genre_str)
    return ' '.join([g['name'] for g in genres]).lower()
  except:
    return ''
df['genres'] = df['genres'].apply(clean_genres)

"""Cek dataset sebelum proses modeling"""

df.head()

"""Simpan dataset dengan bentuk `.csv`"""

df.to_csv("data/movies_dataset.csv", index=False)

"""## Modeling
Di tahap ini, dataset yang bersih bisa digunakan untuk pemodelan. Untuk proyek sistem rekomendasi ini, akan digunakan empat skema dengan dua model berbeda, yaitu:

### 1. TF-IDF + Cosine Similarity (kolom `overview`)

- _Term Frequency - Inverse Document Frequency_ (TF-IDF) merupakan teknik yang digunakan untuk menghitung bobot dari setiap kata dalam dokumen.
- _Cosine Similarity_ digunakan untuk menghitung kemiripan antara dua vektor.

Inisiasi vectorizer tf-idf
"""

tfv_overview = TfidfVectorizer()

"""Fitting TF-IDF ke kolom `overview`"""

tfidf_overview_matrix = tfv_overview.fit_transform(df['overview'])
tfidf_overview_matrix

"""Ukuran matriks TF-IDF `overview`"""

tfidf_overview_matrix.shape

"""Inisisasi fungsi *cosine similarity*"""

cos_tfidf_overview = cosine_similarity(tfidf_overview_matrix)
cos_tfidf_overview[0]

"""Balik pemetaan antara `index` dan `original_title`"""

indices = pd.Series(df.index, index=df['original_title']).drop_duplicates()
indices

"""Buat fungsi sistem rekomendasi dan testing fungsi"""

def recommend_tfidf_cossim_overview(title, cos_tfidf_overview=cos_tfidf_overview):
  # Get the original_title index
  idx = indices[title]

  # Get the pairwise similarity scores
  cos_tfidf_overview_scores = list(enumerate(cos_tfidf_overview[idx]))

  # Sort movies
  cos_tfidf_overview_scores = sorted(cos_tfidf_overview_scores, key=lambda x: x[1], reverse=True)

  # Scores of the top 10 most similar movies
  cos_tfidf_overview_scores = cos_tfidf_overview_scores[1:6]

  # Movie indices
  movie_indices = [i[0] for i in cos_tfidf_overview_scores]

  return df['original_title'].iloc[movie_indices]

"""Uji coba fungsi"""

tfidf_overview_test = recommend_tfidf_cossim_overview('Avatar')
print("5 Recommend Films Based on Avatar:")
tfidf_overview_test

"""Cek nilai *cosine similarity* untuk 10 film rekomendasi teratas"""

sorted(list(enumerate(cos_tfidf_overview[indices['Avatar']])), key=lambda x: x[1], reverse=True)

"""### 2. TF-IDF + Cosine Similarity (Kolom `genres`)
Pemodelan ini bertujuan untuk membandingkan hasil rekomendasi dengan model yang sama dengan menggunakan kolom `overview`

Inisisasi vectorizer TF-IDF
"""

tfv_genres = TfidfVectorizer()

"""fitting TF-IDF ke kolom `genres`"""

tfidf_genres_matrix = tfv_genres.fit_transform(df['genres'])
tfidf_genres_matrix

"""Ukuran matriks TF-IDF `genres`"""

tfidf_genres_matrix.shape

"""Inisiasi fungsi *cosine similarity*"""

cos_tfidf_genres = cosine_similarity(tfidf_genres_matrix)
cos_tfidf_genres[0]

"""Buat fungsi sistem rekomendasi"""

def recommend_tfidf_cossim_genres(title, cos_tfidf_genres=cos_tfidf_genres):
  # Get the original_title index
  idx = indices[title]

  # Get the pairwise similarity scores
  cos_tfidf_genres_scores = list(enumerate(cos_tfidf_genres[idx]))

  # Sort movies
  cos_tfidf_genres_scores = sorted(cos_tfidf_genres_scores, key=lambda x: x[1], reverse=True)

  # Scores of the top 10 most similar movies
  cos_tfidf_genres_scores = cos_tfidf_genres_scores[1:6]

  # Movie indices
  movie_indices = [i[0] for i in cos_tfidf_genres_scores]

  return df['original_title'].iloc[movie_indices]

"""Uji coba fungsi"""

tfidf_genres_test = recommend_tfidf_cossim_genres('Avatar')
print("5 Recommend Films Based on Avatar:")
tfidf_genres_test

"""Cek nilai *cosine similarity* untuk 10 film rekomendasi teratas"""

sorted(list(enumerate(cos_tfidf_genres[indices['Avatar']])), key=lambda x: x[1], reverse=True)

"""### 3. BERT + Cosine Similarity (Kolom `overview`)
BERT (Bidirectional Encoder Representations from Transformers) merupakan salah satu model yang paling populer dalam bidang NLP. BERT menggunakan teknik self-supervised learning untuk menghasilkan representasi kata yang lebih baik. Untuk pemodelan ini, kembali digunakan *cosine similarity* untuk melihat hubungan antara *embeddings* BERT.

Inisiasi model BERT
"""

model_overview = SentenceTransformer('all-MiniLM-L6-v2') # Salah satu model BERT yang cepat, namun bagus

"""Encoding kolom `overview`"""

embeddings_overview = model_overview.encode(df['overview'].tolist(), show_progress_bar=True)

"""Inisisasi fungsi *cosine similarity*"""

cos_bert_overview = cosine_similarity(embeddings_overview, embeddings_overview)

"""Membuat fungsi sistem rekomendasi"""

def recommend_bert_overview(title, top_n):
  idx = df[df['original_title'].str.lower() == title.lower()].index[0]
  # Pick recommended rows
  row = cos_bert_overview[idx]

  # Sort by the most similar
  similar_indices = row.flatten().argsort()[::-1]

  # Drop it's own movie
  similar_indices = similar_indices[similar_indices != idx]

  # Pick top_n
  top_indices = similar_indices[:top_n]

  # Take a result
  results = []
  for i in top_indices:
    results.append((df.iloc[i]['original_title'], round(row[i], 4)))
  return results

"""Uji coba fungsi"""

bert_overview_test = recommend_bert_overview('Avatar', top_n=5)
print("5 Recommend Films Based on Avatar:")
bert_overview_test

"""### 4. BERT + Cosine Similarity (Kolom `genres`)
Pemodelan ini bertujuan untuk membandingkan hasil rekomendasi dengan model yang sama dengan menggunakan kolom `overview`

Inisiasi model BERT
"""

model_genres = SentenceTransformer('all-MiniLM-L6-v2')

"""Encoding kolom `genres`"""

embeddings_genres = model_genres.encode(df['genres'].tolist(), show_progress_bar=True)

"""Membuat fungsi *cosine similarity*"""

cos_bert_genres = cosine_similarity(embeddings_genres, embeddings_genres)

"""Membuat fungsi sistem rekomendasi"""

def recommend_bert_genres(title, top_n):
  idx = df[df['original_title'].str.lower() == title.lower()].index[0]
  # Pick recommended rows
  row = cos_bert_genres[idx]

  # Sort by the most similar
  similar_indices = row.flatten().argsort()[::-1]

  # Drop it's own movie
  similar_indices = similar_indices[similar_indices != idx]

  # Pick top_n
  top_indices = similar_indices[:top_n]

  # Take a result
  results = []
  for i in top_indices:
    results.append((df.iloc[i]['original_title'], round(row[i], 4)))
  return results

"""Uji coba fungsi"""

bert_genres_test = recommend_bert_genres('Avatar', top_n=5)
print("5 Recommend Films Based on Avatar:")
bert_genres_test

"""## Evaluation
Di tahap ini, kedua model dengan empat skema berbeda akan dievaluasi untuk mengetahui mana yang lebih baik. Evaluasi ini akan dilakukan dengan menggunakan  **_Mean Reciprocal Rank_** (MRR) dan **_Normalized Discounted Cumulative Gain_** (NDCG) sebagai metrik evaluasi. MRR akan digunakan untuk menilai kemampuan model dalam menemukan jawaban yang tepat, sedangkan NDCG akan digunakan untuk menilai kemampuan model dalam menemukan jawaban yang relevan.

Karena kedua metrik tersebut membutuhkan *Ground Truth* untuk menguji keakuratan model, maka selanjutnya akan dibuat *Ground Truth* untuk kebutuhan evaluasi kedua model.

### 1. Ground Truth
Pembuatan *ground truth* ini berdasarkan kepopuleran film dari 10 genre yang telah ditentukan. Berikut hasilnya:
"""

# Parsing 'genres' column to list
df['genres'] = df['genres'].apply(lambda x: x.split() if isinstance(x, str) else [])

# Make a ground truth dict
ground_truth = {}

# Set all unique genres
all_genres = set(g for genres_list in df['genres'] for g in genres_list)

for genre in all_genres:
    # Filter all films with the current genre
    df_genre = df[df['genres'].apply(lambda x: genre in x)]

    # Sort by top 5 most popular
    df_genre_top5 = df_genre.sort_values(by='popularity', ascending=False).head(6)

    for idx, row in df_genre_top5.iterrows():
        film_id = row['id']
        relevant_films = df_genre_top5[df_genre_top5['id'] != film_id]['id'].tolist()
        ground_truth[film_id] = relevant_films

"""Cek ground truth"""

ground_truth

"""Simpan ground truth"""

with open('data/ground_truth.json', 'w') as f:
  json.dump(ground_truth, f)

print(f'Ground truth has been saved! Total: {len(ground_truth)} film queries')

"""Ambil ID film dari film query Avatar (ID: 19995)"""

avatar_ids = ground_truth[19995]
avatar_ids

"""Konversi ground truth Avatar ke judul film"""

# Convert ground truth ID to movie title
ground_truth_titles = {}
for film_id, gt_ids in ground_truth.items():
  # Movie title
  main_title = df[df['id'] == int(film_id)]['original_title'].values[0]

  # Movie title on ground truth
  gt_titles = df[df['id'].isin(gt_ids)]['original_title'].tolist()

  ground_truth_titles[main_title] = gt_titles

print(ground_truth_titles)

"""Ambil rekomendasi film Avatar"""

avatar_recs = ground_truth_titles['Avatar']
avatar_recs

"""### 2. Model Evaluation
Setelah membuat ground truth khusus, maka proses evaluasi bisa dilanjutkan, dengan menggunakan metrik Mean Reciprocal Rank (MRR) dan Normalized Discounted Cumulative Gain (NDCG). MRR dan NDCG digunakan untuk mengukur kinerja model dalam menemukan item yang relevan.

Membuat fungsi mengambil rekaman rekomendasi film dari semua model
"""

def get_top_recommendations(similarity_matrix, ids, top_n):
  recs = {}
  for idx, row in enumerate(similarity_matrix):
    similar_indices = row.flatten().argsort()[::-1]
    similar_indices = [i for i in similar_indices if i != idx][:top_n]
    film_id = ids[idx]
    recommended_ids = [ids[i] for i in similar_indices]
    recs[film_id] = recommended_ids
  return recs

"""Simpan semua hasil rekomendasi"""

model_results = {
	'TF-IDF Overview': get_top_recommendations(cos_tfidf_overview, df['id'], top_n=5),
	'TF-IDF Genres': get_top_recommendations(cos_tfidf_genres, df['id'], top_n=5),
	'BERT Overview': get_top_recommendations(cos_bert_overview, df['id'], top_n=5),
	'BERT Genres': get_top_recommendations(cos_bert_genres, df['id'], top_n=5)
}

"""Buat dict hasil rekomendasi tiap skema"""

recs_tfidf_overview = get_top_recommendations(cos_tfidf_overview, df['id'], top_n=5)
recs_tfidf_genres = get_top_recommendations(cos_tfidf_genres, df['id'], top_n=5)
recs_bert_overview = get_top_recommendations(cos_bert_overview, df['id'], top_n=5)
recs_tfidf_genres =  get_top_recommendations(cos_bert_genres, df['id'], top_n=5)

"""Buat fungsi metrik MRR dan NDCG"""

from sklearn.metrics import ndcg_score

# MRR Function
def mean_reciprocal_rank(ground_truth, prediction):
  rr = 0.0
  for i, p in enumerate(prediction, start=1):
    if p in ground_truth:
      rr = 1.0 / i
      break
  return rr

# NDCG Function
def ndcg(ground_truth, prediction, k=10):
  # Binary relevance (1 if in ground truth, 0 if is not)
  relevance = [1 if p in ground_truth else 0 for p in prediction[:k]]
  return ndcg_score([relevance], [list(range(len(relevance), 0, -1))])

"""Buat proses looping untuk mengambil nilai MRR dan NDCG"""

# Looping for TF-IDF overview
for model_name, avatar_ids in model_results.items():
  mrr_list_tfidf_overview, ndcg_list_tfidf_overview = [], []
  for film_id, prediction in avatar_ids.items():
    gt = ground_truth.get(str(film_id), [])
    mrr_list_tfidf_overview.append(mean_reciprocal_rank(gt, prediction))
    ndcg_list_tfidf_overview.append(ndcg(gt, prediction))
  mrr_result_tfidf_overview = sum(mrr_list_tfidf_overview) / len(mrr_list_tfidf_overview)
  ndcg_result_tfidf_overview = sum(ndcg_list_tfidf_overview) / len(ndcg_list_tfidf_overview)

# Looping for TF-IDF genres
for model_name, avatar_ids in model_results.items():
  mrr_list_tfidf_genres, ndcg_list_tfidf_genres = [], []
  for film_id, prediction in avatar_ids.items():
    gt = ground_truth.get(str(film_id), [])
    mrr_list_tfidf_genres.append(mean_reciprocal_rank(gt, prediction))
    ndcg_list_tfidf_genres.append(ndcg(gt, prediction))
  mrr_result_tfidf_genres = sum(mrr_list_tfidf_genres) / len(mrr_list_tfidf_genres)
  ndcg_result_tfidf_genres = sum(ndcg_list_tfidf_genres) / len(ndcg_list_tfidf_genres)

# Looping for BERT overview
for model_name, avatar_ids in model_results.items():
  mrr_list_bert_overview, ndcg_list_bert_overview = [], []
  for film_id, prediction in avatar_ids.items():
    gt = ground_truth.get(str(film_id), [])
    mrr_list_bert_overview.append(mean_reciprocal_rank(gt, prediction))
    ndcg_list_bert_overview.append(ndcg(gt, prediction))
  mrr_result_bert_overview = sum(mrr_list_bert_overview) / len(mrr_list_bert_overview)
  ndcg_result_bert_overview = sum(ndcg_list_bert_overview) / len(ndcg_list_bert_overview)

# Looping for BERT genres
for model_name, avatar_ids in model_results.items():
  mrr_list_bert_genres, ndcg_list_bert_genres = [], []
  for film_id, prediction in avatar_ids.items():
    gt = ground_truth.get(str(film_id), [])
    mrr_list_bert_genres.append(mean_reciprocal_rank(gt, prediction))
    ndcg_list_bert_genres.append(ndcg(gt, prediction))
  mrr_result_bert_genres = sum(mrr_list_bert_genres) / len(mrr_list_bert_genres)
  ndcg_result_bert_genres = sum(ndcg_list_bert_genres) / len(ndcg_list_bert_genres)

"""Tampilkan nilai metrik"""

metric_result = pd.DataFrame({
	'Model': ['TF-IDF Overview', 'TF-IDF Genres', 'BERT Overview', 'BERT Genres'],
  'MRR': [mrr_result_tfidf_overview, mrr_result_tfidf_genres, mrr_result_bert_overview, mrr_result_bert_genres],
  'NDCG': [ndcg_result_tfidf_overview, ndcg_result_tfidf_genres, ndcg_result_bert_overview, ndcg_result_bert_genres]
})
metric_result

"""Hasil metrik evaluasi MRR dan NDCG di semua model menghasilkan 0. Hal ini mengindikasikan bahwa rekomendasi yang dihasilkan oleh masing-masing model tidak menemukan relevansi langsung dengan ground truth yang telah dibuat. Penyebab utamanya kemungkinan karena data ground truth dan data id film pada hasil rekomendasi (recs) tidak sinkron atau tidak cocok secara langsung. Oleh karena itu, evaluasi manual akan digunakan untuk verifikasi kinerja model secara lebih akurat.

### 3. Manual Evaluation
Evaluasi manual dilakukan dengan membandingkan _ground truth_ yang telah dibuat dengan hasil rekomendasi dari kedua model.

Buat dataframe perbandingan _ground truth_ dengan hasil rekomendasi kedua model
"""

def compute_relevance(recommended, avatar_recs):
    return len(set(recommended).intersection(set(avatar_recs)))

# Count relevances using recs functions
relevance_tfidf_overview = compute_relevance(tfidf_overview_test, avatar_recs)
relevance_tfidf_genres = compute_relevance(tfidf_genres_test, avatar_recs)
relevance_bert_overview = compute_relevance(bert_overview_test, avatar_recs)
relevance_bert_genres = compute_relevance(bert_genres_test, avatar_recs)

film_title = "Avatar"

evaluation_df = pd.DataFrame({
    'Film': [film_title],
    'TF-IDF overview': [tfidf_overview_test],
    'TF-IDF genres': [tfidf_genres_test],
    'BERT overview': [bert_overview_test],
    'BERT genres': [bert_genres_test],
    'TF-IDF overview relevance': [relevance_tfidf_overview],
    'TF-IDF genres relevance': [relevance_tfidf_genres],
    'BERT overview relevance': [relevance_bert_overview],
    'BERT genres relevance': [relevance_bert_genres]
})

# Lihat dataframe
evaluation_df

"""Hasil Evaluasi manual dengan _ground truth_ ternyata menunjukkan hal yang sama dengan hasil evaluasi dengan metrik MRR dan NDCG. Hal ini tentu menjadi pertimbangan dalam menentukan _ground truth_ yang sesuai dengan sistem rekomendasi yang dibangun. Namun, untuk melihat perbandingan secara langsung keempat skema pemodelan tersebut dalam menentukan rekomendasi film dari judul (untuk proyek ini, misalkan **Avatar**), akan dipaparkan hasil dari keempat skema pemodelan tersebut

Ambil judul film hasil rekomendasi dari setiap skema
"""

bert_overview_titles = [title for title, _ in bert_overview_test]
bert_genres_titles = [title for title, _ in bert_genres_test]
tfidf_overview_titles = tfidf_overview_test.tolist()
tfidf_genres_titles = tfidf_genres_test.tolist()

"""Buat dataframe hasil rekomendasi tiap skema"""

# Make a set of recommendation lists
recommendation_lists = {
    'TF-IDF Overview': tfidf_overview_titles,
    'TF-IDF Genres': tfidf_genres_titles,
    'BERT Overview': bert_overview_titles,
    'BERT Genres': bert_genres_titles
}

film_input = 'Avatar'

manual_eval = pd.DataFrame([
    {"Model": model, "Movie Title": film_input, "Recommendation": title}
    for model, titles in recommendation_lists.items()
    for title in titles
])
manual_eval

"""Berdasarkan hasil rekomendasi dari keempat pendekatan content-based filtering terhadap film Avatar, terlihat bahwa setiap skema menghasilkan pola rekomendasi yang berbeda. Pendekatan TF-IDF pada overview cenderung merekomendasikan film dengan kemiripan secara literal dalam teks sinopsis, namun tidak selalu relevan secara tematik — misalnya Apollo 18 atau The American, yang memiliki kata kunci serupa namun latar cerita sangat berbeda. Sebaliknya, TF-IDF pada genres menunjukkan hasil yang sedikit lebih baik, dengan munculnya film-film superhero dan fiksi ilmiah seperti Man of Steel, X-Men: Days of Future Past, dan Jupiter Ascending, meskipun tetap belum menyentuh film dalam ground truth. Pendekatan BERT pada overview memberikan hasil yang lebih semantik dan relevan, seperti Aliens, Serenity, dan Alien: Resurrection, yang memiliki kemiripan konteks dunia luar angkasa, spesies asing, dan konflik manusia-alien—tema yang sangat dekat dengan Avatar. Terakhir, BERT pada genres juga merekomendasikan film superhero dan sci-fi klasik, seperti Superman, X-Men, dan Superman II, namun kembali terbatas oleh input genre yang sangat singkat. Secara keseluruhan, pendekatan BERT dengan overview terlihat paling mendekati konteks naratif dan atmosfer Avatar, meskipun masih belum berhasil mencocokkan film yang ada dalam ground truth secara eksplisit."""